<!DOCTYPE html>
<!--
	Massively by HTML5 UP	html5up.net | @ajlkn	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)-->
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <title>Nuno Lopes - Data Analyst</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <link rel="stylesheet" href="assets/css/main.css">
    <noscript><link rel="stylesheet" href="assets/css/noscript.css"></noscript>
  </head>
  <body class="is-preload">
    <!-- Wrapper -->
    <div id="wrapper">
      <!-- Header -->
      <header id="header"> <a href="index.html" class="logo">Portfolio</a> </header>
      <!-- Nav -->
      <nav id="nav">
        <ul class="links">
          <li class="active"><a href="index.html">Portfolio</a></li>
          <li><a href="about.html">About</a></li>
        </ul>
        <ul class="icons">
          <li><a href="https://www.linkedin.com/in/njlopes/" class="icon brands fa-linkedin"><span
                class="label">LinkedIN</span></a></li>
          <li><a href="#" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
        </ul>
      </nav>
      <!-- Main -->
      <div id="main">
        <!-- Post -->
        <section class="post">
          <header>
            <h2>ETL Process with python pandas</h2>
          </header>
          <h3>Overview</h3>
          <p>This project is a simple demonstration of an ETL process (Extract
            Transform and Load). This type of process allows us to quicly upload
            our data to the database and have it ready for reporting...</p>
          <p>A ETL pipeline follows a 3 step process:</p>
          <ol>
            <li>Extract data from a single or multiple sources.</li>
            <li>Transform the data as necessary by our business logic.</li>
            <li>Loading the data into the target data source or data warehouse.</li>
          </ol>
          <span class="image fit"><img src="images/de1_etl.jpg" alt=""></span>
          <h3>Data</h3>
          <p>The dataset used is public and related to the Coronavirus pandemic
            and can be downloaded from <a href="https://ourworldindata.org/">ourworldindata.org.</a></p>
          <p> Hannah Ritchie, Esteban Ortiz-Ospina, Diana Beltekian, Edouard
            Mathieu, Joe Hasell, Bobbie Macdonald, Charlie Giattino, Cameron
            Appel, Lucas Rodés-Guirao and Max Roser (2020) - "Coronavirus
            Pandemic (COVID-19)". Published online at OurWorldInData.org.
            Retrieved from: 'https://ourworldindata.org/coronavirus' [Online
            Resource] </p>
          <h3>Software</h3>
          <span class="image fit"><img src="images/de1_1.jpg" alt=""></span>
          <p>All codding was done in an Azure Data Studio notebook by using
            Python with the exception of the SQL queries that were executed from
            the notebook with an establish connection to the SQL Server Express.</p>
          <p>The main python libraries used were Pandas for the Extraction and
            Transformation parts of the ETL process and the PYODBC library to
            establish the connection to the SQL Server and do the Load phase.</p>
          <h3>Code</h3>
          <h4>Python Libraries</h4>
          <pre><code>import os
import glob 
import pandas as pd
from datetime import datetime
import pyodbc				</code></pre>
          <h4>1. Load data </h4>
          <p>Pandas will be used to read the csv data file and it is a very
            common Python library for data analysis. I will start to define a
            simple function to load the csv data file:</p>
          <pre><code>def extract_from_csv(file): 
    dataframe = pd.read_csv(file) 
    return dataframe				</code></pre>
          <h4>2. Transform data</h4>
          <p>Our business request is to prepare data regarding the evolution
            Coronavirus available publicly in the <a href="https://ourworldindata.org/">ourworldindata.org.</a>.
            The data set will be split into 3 tables, deaths, vaccinations and
            indicators. All data will be transformed into strings for import
            into SQL Server staging tables.</p>
          <p> The transformation is done by defining the following functions:</p>
          <pre><code>#Create dataframes
def covid_deaths(dataframe):
    covid_deaths = df[[
         'iso_code'
        ,'continent'
        ,'location'
        ,'date'
        ,'population'
        ,'total_cases'
        ,'new_cases'
        ,'new_cases_smoothed'
        ,'total_deaths'
        ,'new_deaths'
        ,'new_deaths_smoothed'
        ,'total_cases_per_million'
        ,'new_cases_per_million'
        ,'new_cases_smoothed_per_million'
        ,'total_deaths_per_million'
        ,'new_deaths_per_million'
        ,'new_deaths_smoothed_per_million'
        ,'reproduction_rate'
        ,'icu_patients'
        ,'icu_patients_per_million'
        ,'hosp_patients'
        ,'hosp_patients_per_million'
        ,'weekly_icu_admissions'
        ,'weekly_icu_admissions_per_million'
        ,'weekly_hosp_admissions'
        ,'weekly_hosp_admissions_per_million'
        ]]

    covid_deaths = covid_deaths.astype(str)

    return covid_deaths

def covid_vaccinations(dataframe):
    covid_vaccinations = df[[
         'iso_code'
        ,'continent'
        ,'location'
        ,'date'
        ,'new_tests'
        ,'total_tests'
        ,'total_tests_per_thousand'
        ,'new_tests_per_thousand'
        ,'new_tests_smoothed'
        ,'new_tests_smoothed_per_thousand'
        ,'positive_rate'
        ,'tests_per_case'
        ,'tests_units'
        ,'total_vaccinations'
        ,'people_vaccinated'
        ,'people_fully_vaccinated'
        ,'new_vaccinations'
        ,'new_vaccinations_smoothed'
        ,'total_vaccinations_per_hundred'
        ,'people_vaccinated_per_hundred'
        ,'people_fully_vaccinated_per_hundred'
        ,'new_vaccinations_smoothed_per_million'
        ]]

    covid_vaccinations = covid_vaccinations.astype(str)

    return covid_vaccinations

def indicators(dataframe):
    indicators = df[[
         'iso_code'
        ,'continent'
        ,'location'
        ,'date'
        ,'stringency_index'
        ,'population_density'
        ,'median_age'
        ,'aged_65_older'
        ,'aged_70_older'
        ,'gdp_per_capita'
        ,'extreme_poverty'
        ,'cardiovasc_death_rate'
        ,'diabetes_prevalence'
        ,'female_smokers'
        ,'male_smokers'
        ,'handwashing_facilities'
        ,'hospital_beds_per_thousand'
        ,'life_expectancy'
        ,'human_development_index'
        ,'excess_mortality'
        ]]

    indicators = indicators.astype(str)

    return indicators 				</code></pre>
          <p> Another important thing is to create a log of our process and
            store it into a txt file. This file will provide information such as
            when our data was updated and which parts of our pipeline worked in
            case of failure. </p>
          <pre><code>#Logging
def log(message):
    timestamp_format = '%H:%M:%S|%d-%m-%Y'
    #Hour-Minute-Second-MonthName-Day-Year
    now = datetime.now() # get current time
    timestamp = now.strftime(timestamp_format)
    print(message + ': ' + timestamp)
    with open('ETL_logfile.txt','a') as f: f.write(timestamp + '|' + message + '\n') 			</code></pre>
          <h4>3. Load the data to SQL Server</h4>
          <p>Preparing a connection, so let us check our available drivers</p>
          <pre><code>#Listing drivers available
for driver in pyodbc.drivers():
    print(driver)				</code></pre>
          <p>Our connection string should use one of the drivers above. The
            server in this case is SQL Server Express where we have a database
            called Coronavirus to where we will upload our data. Note that
            Windows Authentication will be used to connect to our database.</p>
          <pre><code>#Setup a SQL Server connection
conn_str = (
    r'Driver=SQL Server Native Client 11.0;'
    r'Server=.\SQLEXPRESS;'
    r'Database=Coronavirus;'
    r'Trusted_Connection=yes;')</code></pre>
          <p> With a connection created to the database Coronavirus, we can
            create the tables we need to populate, but first we need to check if
            they are already created and if so, drop them. Data will be loaded
            to staging tables and after we will convert the data to the relevant
            data types. The staging tables will be cleared every time we load
            data in. Note that in this scenario we will also refresh the data in
            the main tables and will clear all pre existing data. </p>
          <pre><code>#Check if table is already created and drop it
def clear_staging_tables():
    cnxn = pyodbc.connect(conn_str)
    cursor = cnxn.cursor()

    cursor.execute('DROP TABLE IF EXISTS Coronavirus.staging.covid_deaths')
    cnxn.commit()

    cursor.execute('DROP TABLE IF EXISTS Coronavirus.staging.covid_vaccination')
    cnxn.commit()

    cursor.execute('DROP TABLE IF EXISTS Coronavirus.staging.indicators')
    cnxn.commit()

    cnxn.close()

def clear_tables():
    cnxn = pyodbc.connect(conn_str)
    cursor = cnxn.cursor()

    cursor.execute('DROP TABLE IF EXISTS Coronavirus.dbo.covid_deaths')
    cnxn.commit()

    cursor.execute('DROP TABLE IF EXISTS Coronavirus.dbo.covid_vaccination')
    cnxn.commit()

    cursor.execute('DROP TABLE IF EXISTS Coronavirus.dbo.indicators')
    cnxn.commit()

    cnxn.close()				</code></pre>
          <p>The staging tables will be created and uploaded as strings to avoid
            errors in the loading process. </p>
          <pre><code>#Creating the Staging tables in SQL server
def create_staging_tables():
  cnxn = pyodbc.connect(conn_str)
  cursor = cnxn.cursor()

  cursor.execute('''CREATE TABLE staging.covid_deaths (
            iso_code NVARCHAR(50)
          , continent NVARCHAR(50)
          , location NVARCHAR(50)
          , date NVARCHAR(50)
          , population NVARCHAR(50)
          , total_cases NVARCHAR(50)
          , new_cases NVARCHAR(50)
          , new_cases_smoothed NVARCHAR(50)
          , total_deaths NVARCHAR(50)
          , new_deaths NVARCHAR(50)
          , new_deaths_smoothed NVARCHAR(50)
          , total_cases_per_million NVARCHAR(50)
          , new_cases_per_million NVARCHAR(50)
          , new_cases_smoothed_per_million NVARCHAR(50)
          , total_deaths_per_million NVARCHAR(50)
          , new_deaths_per_million NVARCHAR(50)
          , new_deaths_smoothed_per_million NVARCHAR(50)
          , reproduction_rate NVARCHAR(50)
          , icu_patients NVARCHAR(50)
          , icu_patients_per_million NVARCHAR(50)
          , hosp_patients NVARCHAR(50)
          , hosp_patients_per_million NVARCHAR(50)
          , weekly_icu_admissions NVARCHAR(50)
          , weekly_icu_admissions_per_million NVARCHAR(50)
          , weekly_hosp_admissions NVARCHAR(50)
          , weekly_hosp_admissions_per_million NVARCHAR(50))''')

  cnxn.commit()

  cursor.execute('''CREATE TABLE staging.covid_vaccination (
            iso_code NVARCHAR(50)       
          , continent NVARCHAR(50)   
          , location  NVARCHAR(50)   
          , date NVARCHAR(50)
          , new_tests NVARCHAR(50)
          , total_tests NVARCHAR(50)
          , total_tests_per_thousand NVARCHAR(50)
          , new_tests_per_thousand NVARCHAR(50)
          , new_tests_smoothed NVARCHAR(50)
          , new_tests_smoothed_per_thousand NVARCHAR(50)
          , positive_rate NVARCHAR(50)
          , tests_per_case NVARCHAR(50)
          , tests_units NVARCHAR(50)
          , total_vaccinations NVARCHAR(50)
          , people_vaccinated NVARCHAR(50)
          , people_fully_vaccinated NVARCHAR(50)
          , new_vaccinations NVARCHAR(50)
          , new_vaccinations_smoothed NVARCHAR(50)
          , total_vaccinations_per_hundred NVARCHAR(50)
          , people_vaccinated_per_hundred NVARCHAR(50)
          , people_fully_vaccinated_per_hundred NVARCHAR(50)
          , new_vaccinations_smoothed_per_million NVARCHAR(50))''')

  cnxn.commit()

  cursor.execute('''CREATE TABLE staging.indicators (         
            iso_code NVARCHAR(50)
          , continent NVARCHAR(50)
          , location NVARCHAR(50)
          , date NVARCHAR(50)
          , stringency_index NVARCHAR(50)
          , population_density NVARCHAR(50)
          , median_age NVARCHAR(50)
          , aged_65_older NVARCHAR(50)
          , aged_70_older NVARCHAR(50)
          , gdp_per_capita NVARCHAR(50)
          , extreme_poverty NVARCHAR(50)
          , cardiovasc_death_rate NVARCHAR(50)
          , diabetes_prevalence NVARCHAR(50)
          , female_smokers NVARCHAR(50)
          , male_smokers NVARCHAR(50)
          , handwashing_facilities NVARCHAR(50)
          , hospital_beds_per_thousand NVARCHAR(50)
          , life_expectancy NVARCHAR(50)
          , human_development_index NVARCHAR(50)
          , excess_mortality NVARCHAR(50))''')

  cnxn.commit()

  cnxn.close()				</code></pre>
          <p>The final tables can also be created with the columns we require,
            which may differ from the staging tables and also converted to the
            required data types. </p>
          <pre><code>#Create the final tables to receive the converted data from the staging tables
def create_tables():
  cnxn = pyodbc.connect(conn_str)
  cursor = cnxn.cursor()

  cursor.execute('''CREATE TABLE covid_deaths (
            iso_code NVARCHAR(50)
          , continent NVARCHAR(50)
          , location NVARCHAR(50)
          , date DATETIME
          , population NUMERIC(18,3)
          , total_cases NUMERIC(18,3)
          , new_cases NUMERIC(18,3)
          , new_cases_smoothed NUMERIC(18,3)
          , total_deaths NUMERIC(18,3)
          , new_deaths NUMERIC(18,3)
          , new_deaths_smoothed NUMERIC(18,3)
          , total_cases_per_million NUMERIC(18,3)
          , new_cases_per_million NUMERIC(18,3)
          , new_cases_smoothed_per_million NUMERIC(18,3)
          , total_deaths_per_million NUMERIC(18,3)
          , new_deaths_per_million NUMERIC(18,3)
          , new_deaths_smoothed_per_million NUMERIC(18,3)
          , reproduction_rate NUMERIC(18,3)
          , icu_patients NUMERIC(18,3)
          , icu_patients_per_million NUMERIC(18,3)
          , hosp_patients NUMERIC(18,3)
          , hosp_patients_per_million NUMERIC(18,3)
          , weekly_icu_admissions NUMERIC(18,3)
          , weekly_icu_admissions_per_million NUMERIC(18,3)
          , weekly_hosp_admissions NUMERIC(18,3)
          , weekly_hosp_admissions_per_million NUMERIC(18,3))''')

  cnxn.commit()

  cursor.execute('''CREATE TABLE covid_vaccination (
            iso_code NVARCHAR(50)       
          , continent NVARCHAR(50)   
          , location  NVARCHAR(50)   
          , date DATETIME
          , new_tests NUMERIC(18,3)
          , total_tests NUMERIC(18,3)
          , total_tests_per_thousand NUMERIC(18,3)
          , new_tests_per_thousand NUMERIC(18,3)
          , new_tests_smoothed NUMERIC(18,3)
          , new_tests_smoothed_per_thousand NUMERIC(18,3)
          , positive_rate NUMERIC(18,3)
          , tests_per_case NUMERIC(18,3)
          , tests_units NVARCHAR(50) 
          , total_vaccinations NUMERIC(18,3)
          , people_vaccinated NUMERIC(18,3)
          , people_fully_vaccinated NUMERIC(18,3)
          , new_vaccinations NUMERIC(18,3)
          , new_vaccinations_smoothed NUMERIC(18,3)
          , total_vaccinations_per_hundred NUMERIC(18,3)
          , people_vaccinated_per_hundred NUMERIC(18,3)
          , people_fully_vaccinated_per_hundred NUMERIC(18,3)
          , new_vaccinations_smoothed_per_million NUMERIC(18,3))''')

  cnxn.commit()

  cursor.execute('''CREATE TABLE indicators (         
            iso_code NVARCHAR(50)
          , continent NVARCHAR(50)
          , location NVARCHAR(50)
          , date DATETIME
          , stringency_index NUMERIC(18,3)
          , population_density NUMERIC(18,3)
          , median_age NUMERIC(18,3)
          , aged_65_older NUMERIC(18,3)
          , aged_70_older NUMERIC(18,3)
          , gdp_per_capita NUMERIC(18,3)
          , extreme_poverty NUMERIC(18,3)
          , cardiovasc_death_rate NUMERIC(18,3)
          , diabetes_prevalence NUMERIC(18,3)
          , female_smokers NUMERIC(18,3)
          , male_smokers NUMERIC(18,3)
          , handwashing_facilities NUMERIC(18,3)
          , hospital_beds_per_thousand NUMERIC(18,3)
          , life_expectancy NUMERIC(18,3)
          , human_development_index NUMERIC(18,3)
          , excess_mortality NUMERIC(18,3))''')

  cnxn.commit()

  cnxn.close()</code></pre>
          <p> After the tables have been created we can define the functions to
            load each table. Note that each table is being transformed into a
            list. </p>
          <pre><code>#Functions to load data into raw tables in SQL Server
def load_staging_covid_deaths(dataframe_to_load):

    df = dataframe_to_load.values.tolist()

    cnxn = pyodbc.connect(conn_str)
    cursor = cnxn.cursor()

    insert_query = '''INSERT INTO staging.covid_deaths (iso_code, continent, location, date
                      ,population, total_cases, new_cases, new_cases_smoothed, total_deaths
                      ,new_deaths, new_deaths_smoothed, total_cases_per_million, new_cases_per_million
                      ,new_cases_smoothed_per_million, total_deaths_per_million, new_deaths_per_million
                      ,new_deaths_smoothed_per_million, reproduction_rate, icu_patients, icu_patients_per_million
                      ,hosp_patients, hosp_patients_per_million, weekly_icu_admissions, weekly_icu_admissions_per_million
                      ,weekly_hosp_admissions, weekly_hosp_admissions_per_million)
                      VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?);'''

    for row in df:
        values = (row[0],row[1],row[2],row[3],row[4],row[5],row[6],row[7],row[8],row[9],row[10],row[11],row[12],row[13],row[14],row[15],row[16],row[17],row[18],row[19],row[20],row[21],row[22],row[23],row[24],row[25])

        cursor.execute(insert_query, values)

    cnxn.commit()
    cnxn.close()



def load_staging_covid_vaccination(dataframe_to_load):

    df = dataframe_to_load.values.tolist()

    cnxn = pyodbc.connect(conn_str)
    cursor = cnxn.cursor()

    insert_query = '''INSERT INTO staging.covid_vaccination (iso_code, continent, location, date
                      ,new_tests, total_tests, total_tests_per_thousand, new_tests_per_thousand
                      ,new_tests_smoothed, new_tests_smoothed_per_thousand
                      ,positive_rate, tests_per_case, tests_units, total_vaccinations
                      ,people_vaccinated, people_fully_vaccinated, new_vaccinations, new_vaccinations_smoothed
                      ,total_vaccinations_per_hundred, people_vaccinated_per_hundred
                      ,people_fully_vaccinated_per_hundred, new_vaccinations_smoothed_per_million)
                      VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?);'''

    for row in df:
        values = (row[0],row[1],row[2],row[3],row[4],row[5],row[6],row[7],row[8],row[9],row[10],row[11],row[12],row[13],row[14],row[15],row[16],row[17],row[18],row[19],row[20],row[21])

        cursor.execute(insert_query, values)

    cnxn.commit()
    cnxn.close()

def load_staging_indicators(dataframe_to_load):

    df = dataframe_to_load.values.tolist()

    cnxn = pyodbc.connect(conn_str)
    cursor = cnxn.cursor()

    insert_query = '''INSERT INTO staging.indicators (iso_code, continent, location, date
                      ,stringency_index, population_density, median_age, aged_65_older, aged_70_older
                      ,gdp_per_capita, extreme_poverty, cardiovasc_death_rate, diabetes_prevalence
                      ,female_smokers, male_smokers, handwashing_facilities, hospital_beds_per_thousand
                      ,life_expectancy, human_development_index, excess_mortality)
                      VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?);'''

    for row in df:
        values = (row[0],row[1],row[2],row[3],row[4],row[5],row[6],row[7],row[8],row[9],row[10],row[11],row[12],row[13],row[14],row[15],row[16],row[17],row[18],row[19])

        cursor.execute(insert_query, values)

    cnxn.commit()
    cnxn.close()</code></pre>
          <p> Once the data is on the staging tables the only thing needed is to
            define the final functions that will perform the final
            transformations on our data to make them readily available on our
            server. At this point we can handle with null and perform the
            necessary date, numeric conversions and also create additional
            columns as per business request. </p>
          <pre><code>#Functions that will create the final tables
def transform_covid_deaths():
    cnxn = pyodbc.connect(conn_str)
    cursor = cnxn.cursor()

    cursor.execute('''INSERT INTO [dbo].[covid_deaths] (
                              [iso_code]
                            , [continent]
                            , [location]
                            , [date]
                            , [population]
                            , [total_cases]
                            , [new_cases]
                            , [new_cases_smoothed]
                            , [total_deaths]
                            , [new_deaths]
                            , [new_deaths_smoothed]
                            , [total_cases_per_million]
                            , [new_cases_per_million]
                            , [new_cases_smoothed_per_million]
                            , [total_deaths_per_million]
                            , [new_deaths_per_million]
                            , [new_deaths_smoothed_per_million]
                            , [reproduction_rate]
                            , [icu_patients]
                            , [icu_patients_per_million]
                            , [hosp_patients]
                            , [hosp_patients_per_million]
                            , [weekly_icu_admissions]
                            , [weekly_icu_admissions_per_million]
                            , [weekly_hosp_admissions]
                            , [weekly_hosp_admissions_per_million])

                        SELECT 
                              [iso_code]
                            , [continent]
                            , [location]
                            , CAST([date] as date) as [date]
                            , IIF([population] = 'nan', NULL ,CAST([population] AS NUMERIC(18,3))) as [population]
                            , IIF([total_cases] = 'nan', NULL ,CAST([total_cases] AS NUMERIC(18,3))) AS [total_cases]
                            , IIF([new_cases] = 'nan', NULL ,CAST([new_cases] AS NUMERIC(18,3))) AS [new_cases]
                            , IIF([new_cases_smoothed] = 'nan', NULL ,CAST([new_cases_smoothed] AS NUMERIC(18,3))) AS [new_cases_smoothed]
                            , IIF([total_deaths] = 'nan', NULL ,CAST([total_deaths] AS NUMERIC(18,3))) AS [total_deaths]
                            , IIF([new_deaths] = 'nan', NULL ,CAST([new_deaths] AS NUMERIC(18,3))) AS [new_deaths]
                            , IIF([new_deaths_smoothed] = 'nan', NULL ,CAST([new_deaths_smoothed] AS NUMERIC(18,3))) AS [new_deaths_smoothed]
                            , IIF([total_cases_per_million] = 'nan', NULL ,CAST([total_cases_per_million] AS NUMERIC(18,3))) AS [total_cases_per_million]
                            , IIF([new_cases_per_million] = 'nan', NULL ,CAST([new_cases_per_million] AS NUMERIC(18,3))) AS [new_cases_per_million]
                            , IIF([new_cases_smoothed_per_million] = 'nan', NULL ,CAST([new_cases_smoothed_per_million] AS NUMERIC(18,3))) AS [new_cases_smoothed_per_million]
                            , IIF([total_deaths_per_million] = 'nan', NULL ,CAST([total_deaths_per_million] AS NUMERIC(18,3))) AS [total_deaths_per_million]
                            , IIF([new_deaths_per_million] = 'nan', NULL ,CAST([new_deaths_per_million] AS NUMERIC(18,3))) AS [new_deaths_per_million]
                            , IIF([new_deaths_smoothed_per_million] = 'nan', NULL ,CAST([new_deaths_smoothed_per_million] AS NUMERIC(18,3))) AS [new_deaths_smoothed_per_million]
                            , IIF([reproduction_rate] = 'nan', NULL ,CAST([reproduction_rate] AS NUMERIC(18,3))) AS [reproduction_rate]
                            , IIF([icu_patients] = 'nan', NULL ,CAST([icu_patients] AS NUMERIC(18,1))) AS [icu_patients]
                            , IIF([icu_patients_per_million] = 'nan', NULL ,CAST([icu_patients_per_million] AS NUMERIC(18,3))) AS [icu_patients_per_million]
                            , IIF([hosp_patients] = 'nan', NULL ,CAST([hosp_patients] AS NUMERIC(18,1))) AS [hosp_patients]
                            , IIF([hosp_patients_per_million] = 'nan', NULL ,CAST([hosp_patients_per_million] AS NUMERIC(18,3))) AS [hosp_patients_per_million]
                            , IIF([weekly_icu_admissions] = 'nan', NULL ,CAST([weekly_icu_admissions] AS NUMERIC(18,3))) AS [weekly_icu_admissions]
                            , IIF([weekly_icu_admissions_per_million] = 'nan', NULL ,CAST([weekly_icu_admissions_per_million] AS NUMERIC(18,3))) AS [weekly_icu_admissions_per_million]
                            , IIF([weekly_hosp_admissions] = 'nan', NULL ,CAST([weekly_hosp_admissions] AS NUMERIC(18,3))) AS [weekly_hosp_admissions]
                            , IIF([weekly_hosp_admissions_per_million] = 'nan', NULL ,CAST([weekly_hosp_admissions_per_million] AS NUMERIC(18,3))) AS [weekly_hosp_admissions_per_million]
                        FROM [Staging].[covid_deaths]''')
    cnxn.commit()
    cnxn.close()

def transform_covid_vaccination():
    cnxn = pyodbc.connect(conn_str)
    cursor = cnxn.cursor()

    cursor.execute('''INSERT INTO [dbo].[covid_vaccination] ( 
                                [iso_code]
                              , [continent]
                              , [location]
                              , [date]
                              , [new_tests]
                              , [total_tests]
                              , [total_tests_per_thousand]
                              , [new_tests_per_thousand]
                              , [new_tests_smoothed]
                              , [new_tests_smoothed_per_thousand]
                              , [positive_rate]
                              , [tests_per_case]
                              , [tests_units]
                              , [total_vaccinations]
                              , [people_vaccinated]
                              , [people_fully_vaccinated]
                              , [new_vaccinations]
                              , [new_vaccinations_smoothed]
                              , [total_vaccinations_per_hundred]
                              , [people_vaccinated_per_hundred]
                              , [people_fully_vaccinated_per_hundred]
                              , [new_vaccinations_smoothed_per_million])

                        SELECT          
                                [iso_code]
                              , [continent]
                              , [location]
                              , CAST([date] as date) as [date]
                              , IIF([new_tests] = 'nan', NULL ,CAST([new_tests] AS NUMERIC(18,3))) as [new_tests]
                              , IIF([total_tests] = 'nan', NULL ,CAST([total_tests] AS NUMERIC(18,3))) as [total_tests]
                              , IIF([total_tests_per_thousand] = 'nan', NULL ,CAST([total_tests_per_thousand] AS NUMERIC(18,3))) as [total_tests_per_thousand]
                              , IIF([new_tests_per_thousand] = 'nan', NULL ,CAST([new_tests_per_thousand] AS NUMERIC(18,3))) as [new_tests_per_thousand]
                              , IIF([new_tests_smoothed] = 'nan', NULL ,CAST([new_tests_smoothed] AS NUMERIC(18,3))) as [new_tests_smoothed]
                              , IIF([new_tests_smoothed_per_thousand] = 'nan', NULL ,CAST([new_tests_smoothed_per_thousand] AS NUMERIC(18,3))) as [new_tests_smoothed_per_thousand]
                              , IIF([positive_rate] = 'nan', NULL ,CAST([positive_rate] AS NUMERIC(18,3))) as [positive_rate]
                              , IIF([tests_per_case] = 'nan', NULL ,CAST([tests_per_case] AS NUMERIC(18,3))) as [tests_per_case]
                              , IIF([tests_units] = 'nan', NULL, [tests_units]) 
                              , IIF([total_vaccinations] = 'nan', NULL ,CAST([total_vaccinations] AS NUMERIC(18,3))) as [total_vaccinations]
                              , IIF([people_vaccinated] = 'nan', NULL ,CAST([people_vaccinated] AS NUMERIC(18,3))) as [people_vaccinated]
                              , IIF([people_fully_vaccinated] = 'nan', NULL ,CAST([people_fully_vaccinated] AS NUMERIC(18,3))) as [people_fully_vaccinated]
                              , IIF([new_vaccinations] = 'nan', NULL ,CAST([new_vaccinations] AS NUMERIC(18,3))) as [new_vaccinations]
                              , IIF([new_vaccinations_smoothed] = 'nan', NULL ,CAST([new_vaccinations_smoothed] AS NUMERIC(18,3))) as [new_vaccinations_smoothed]
                              , IIF([total_vaccinations_per_hundred] = 'nan', NULL ,CAST([total_vaccinations_per_hundred] AS NUMERIC(18,3))) as [total_vaccinations_per_hundred]
                              , IIF([people_vaccinated_per_hundred] = 'nan', NULL ,CAST([people_vaccinated_per_hundred] AS NUMERIC(18,3))) as [people_vaccinated_per_hundred]
                              , IIF([people_fully_vaccinated_per_hundred] = 'nan', NULL ,CAST([people_fully_vaccinated_per_hundred] AS NUMERIC(18,3))) as [people_fully_vaccinated_per_hundred]
                              , IIF([new_vaccinations_smoothed_per_million] = 'nan', NULL ,CAST([new_vaccinations_smoothed_per_million] AS NUMERIC(18,3))) as [new_vaccinations_smoothed_per_million]
                        FROM [Staging].[covid_vaccination]''')

    cnxn.commit()
    cnxn.close()


def transform_indicators():
    cnxn = pyodbc.connect(conn_str)
    cursor = cnxn.cursor()

    cursor.execute('''INSERT INTO [dbo].[indicators] ( 
                                [iso_code]
                              , [continent]
                              , [location]
                              , [date]
                              , [stringency_index]
                              , [population_density]
                              , [median_age]
                              , [aged_65_older]
                              , [aged_70_older]
                              , [gdp_per_capita]
                              , [extreme_poverty]
                              , [cardiovasc_death_rate]
                              , [diabetes_prevalence]
                              , [female_smokers]
                              , [male_smokers]
                              , [handwashing_facilities]
                              , [hospital_beds_per_thousand]
                              , [life_expectancy]
                              , [human_development_index]
                              , [excess_mortality])
                    
                        SELECT          
                                [iso_code]
                              , [continent]
                              , [location]
                              , [date]
                              , IIF([stringency_index] = 'nan', NULL ,CAST([stringency_index] AS NUMERIC(18,3))) as [stringency_index]
                              , IIF([population_density] = 'nan', NULL ,CAST([population_density] AS NUMERIC(18,3))) as [population_density]
                              , IIF([median_age] = 'nan', NULL ,CAST([median_age] AS NUMERIC(18,3))) as [median_age]
                              , IIF([aged_65_older] = 'nan', NULL ,CAST([aged_65_older] AS NUMERIC(18,3))) as [aged_65_older]
                              , IIF([aged_70_older] = 'nan', NULL ,CAST([aged_70_older] AS NUMERIC(18,3))) as [aged_70_older]
                              , IIF([gdp_per_capita] = 'nan', NULL ,CAST([gdp_per_capita] AS NUMERIC(18,3))) as [gdp_per_capita]
                              , IIF([extreme_poverty] = 'nan', NULL ,CAST([extreme_poverty] AS NUMERIC(18,3))) as [extreme_poverty]
                              , IIF([cardiovasc_death_rate] = 'nan', NULL ,CAST([cardiovasc_death_rate] AS NUMERIC(18,3))) as [cardiovasc_death_rate]
                              , IIF([diabetes_prevalence] = 'nan', NULL ,CAST([diabetes_prevalence] AS NUMERIC(18,3))) as [diabetes_prevalence]
                              , IIF([female_smokers] = 'nan', NULL ,CAST([female_smokers] AS NUMERIC(18,3))) as [female_smokers]
                              , IIF([male_smokers] = 'nan', NULL ,CAST([male_smokers] AS NUMERIC(18,3))) as [male_smokers]
                              , IIF([handwashing_facilities] = 'nan', NULL ,CAST([handwashing_facilities] AS NUMERIC(18,3))) as [handwashing_facilities]
                              , IIF([hospital_beds_per_thousand] = 'nan', NULL ,CAST([hospital_beds_per_thousand] AS NUMERIC(18,3))) as [hospital_beds_per_thousand]
                              , IIF([life_expectancy] = 'nan', NULL ,CAST([life_expectancy] AS NUMERIC(18,3))) as [life_expectancy]
                              , IIF([human_development_index] = 'nan', NULL ,CAST([human_development_index] AS NUMERIC(18,3))) as [human_development_index]
                              , IIF([excess_mortality] = 'nan', NULL ,CAST([excess_mortality] AS NUMERIC(18,3))) as [excess_mortality]
                        FROM [Staging].[indicators]''')
    
    cnxn.commit()
    cnxn.close()
</code></pre>
          <p> After the data is loaded, checks have to be made to guarantee that
            our data has all been imported. </p>
          <pre><code>def etl_check():
    cnxn = pyodbc.connect(conn_str)
    cursor = cnxn.cursor()
    
    cursor.execute('''SELECT
                    	t.[name],
                    	s.[name],
                    	i.[Rows]
                    FROM sys.tables AS t
                    	JOIN sys.sysindexes AS i 
                    		ON t.[OBJECT_ID] = i.[ID]
                    	JOIN sys.schemas AS s
                    		ON t.[schema_id] = s.[schema_id]
                    WHERE i.indid IN (0,1)
                    ORDER BY t.[name] ASC, s.[name] ASC''')
    
    result = cursor.fetchall()
    print(result)
    
    cnxn.close()     </code></pre>
          <p> With all the functions created we just need to execute them in
            order to have our ETL pipeline defined. Our data, in this case come
            just from one csv file. </p>
          <pre><code>file = 'owid-covid-data.csv'
          
log('SQL ETL Job Started')
#Step_1: EXTRACT
log('Extract phase Started')
df = extract_from_csv(file)
log('Extract phase Ended')

log('Transform phase Started')
#Step_2: TRANSFORM
cd = covid_deaths(df)
cv = covid_vaccinations(df)
ci = indicators(df)
log('Transform phase Ended')

log('SQL Load phase Started')
#Step_3: LOAD
clear_tables()
clear_staging_tables()
create_tables()
create_staging_tables()

load_staging_covid_deaths(cd)
load_staging_covid_vaccination(cv)
load_staging_indicators(ci)
log('SQL Load phase Ended')

log('SQL Transform phase Started')
transform_covid_deaths()
transform_covid_vaccination()
transform_indicators()
log('SQL Transform phase Ended')

log('ETL Job Ended')
          
          </code></pre>
          <p>We can now check if the data was loaded. </p>
          <pre><code>etl_check()</code></pre>
        </section>
      </div>
      <!-- Footer -->
      <footer id="footer">
        <section class="split contact">
          <section>
            <h3>Email</h3>
            <p><a href="mailto:nuno.j.lopes@outlook.com">nuno.j.lopes@outlook.com</a></p>
          </section>
          <section>
            <h3>Social</h3>
            <ul class="icons alt">
              <li><a href="https://www.linkedin.com/in/njlopes/" class="icon brands alt fa-linkedin"><span
                    class="label">LinkedIN</span></a></li>
              <li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
            </ul>
          </section>
        </section>
      </footer>
      <!-- Copyright -->
      <div id="copyright">
        <ul>
          <li>© <a href="mailto:nuno.j.lopes@outlook.com">nuno.j.lopes</a></li>
          <li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
        </ul>
      </div>
    </div>
    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.scrollex.min.js"></script>
    <script src="assets/js/jquery.scrolly.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>
  </body>
</html>
